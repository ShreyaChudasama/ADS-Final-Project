{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from matplotlib.pyplot import GridSpec\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.datasets import make_blobs\n",
    "# import missingno as msno\n",
    "# import pivottablejs\n",
    "# import pandas_profiling\n",
    "# import logging\n",
    "\n",
    "# from __future__ import print_function\n",
    "# from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "# import ipywidgets as widgets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingData= pd.read_csv(\"../dataset/data_job_posts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobpost</th>\n",
       "      <th>date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>AnnouncementCode</th>\n",
       "      <th>Term</th>\n",
       "      <th>Eligibility</th>\n",
       "      <th>Audience</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>Duration</th>\n",
       "      <th>...</th>\n",
       "      <th>Salary</th>\n",
       "      <th>ApplicationP</th>\n",
       "      <th>OpeningDate</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Notes</th>\n",
       "      <th>AboutC</th>\n",
       "      <th>Attach</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>IT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMERIA Investment Consulting Company\\r\\nJOB TI...</td>\n",
       "      <td>Jan 5, 2004</td>\n",
       "      <td>Chief Financial Officer</td>\n",
       "      <td>AMERIA Investment Consulting Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To apply for this position, please submit a\\r\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26 January 2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>International Research &amp; Exchanges Board (IREX...</td>\n",
       "      <td>Jan 7, 2004</td>\n",
       "      <td>Full-time Community Connections Intern (paid i...</td>\n",
       "      <td>International Research &amp; Exchanges Board (IREX)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 months</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please submit a cover letter and resume to:\\r\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12 January 2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The International Research &amp; Exchanges Board (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Caucasus Environmental NGO Network (CENN)\\r\\nJ...</td>\n",
       "      <td>Jan 7, 2004</td>\n",
       "      <td>Country Coordinator</td>\n",
       "      <td>Caucasus Environmental NGO Network (CENN)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Renewable annual contract\\r\\nPOSITION</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please send resume or CV toursula.kazarian@......</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 January 2004\\r\\nSTART DATE:  February 2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Caucasus Environmental NGO Network is a\\r\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manoff Group\\r\\nJOB TITLE:  BCC Specialist\\r\\n...</td>\n",
       "      <td>Jan 7, 2004</td>\n",
       "      <td>BCC Specialist</td>\n",
       "      <td>Manoff Group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please send cover letter and resume to Amy\\r\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23 January 2004\\r\\nSTART DATE:  Immediate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yerevan Brandy Company\\r\\nJOB TITLE:  Software...</td>\n",
       "      <td>Jan 10, 2004</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Yerevan Brandy Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Successful candidates should submit\\r\\n- CV; \\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 January 2004, 18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             jobpost          date  \\\n",
       "0  AMERIA Investment Consulting Company\\r\\nJOB TI...   Jan 5, 2004   \n",
       "1  International Research & Exchanges Board (IREX...   Jan 7, 2004   \n",
       "2  Caucasus Environmental NGO Network (CENN)\\r\\nJ...   Jan 7, 2004   \n",
       "3  Manoff Group\\r\\nJOB TITLE:  BCC Specialist\\r\\n...   Jan 7, 2004   \n",
       "4  Yerevan Brandy Company\\r\\nJOB TITLE:  Software...  Jan 10, 2004   \n",
       "\n",
       "                                               Title  \\\n",
       "0                            Chief Financial Officer   \n",
       "1  Full-time Community Connections Intern (paid i...   \n",
       "2                                Country Coordinator   \n",
       "3                                     BCC Specialist   \n",
       "4                                 Software Developer   \n",
       "\n",
       "                                           Company AnnouncementCode Term  \\\n",
       "0             AMERIA Investment Consulting Company              NaN  NaN   \n",
       "1  International Research & Exchanges Board (IREX)              NaN  NaN   \n",
       "2        Caucasus Environmental NGO Network (CENN)              NaN  NaN   \n",
       "3                                     Manoff Group              NaN  NaN   \n",
       "4                           Yerevan Brandy Company              NaN  NaN   \n",
       "\n",
       "  Eligibility Audience StartDate                               Duration  \\\n",
       "0         NaN      NaN       NaN                                    NaN   \n",
       "1         NaN      NaN       NaN                               3 months   \n",
       "2         NaN      NaN       NaN  Renewable annual contract\\r\\nPOSITION   \n",
       "3         NaN      NaN       NaN                                    NaN   \n",
       "4         NaN      NaN       NaN                                    NaN   \n",
       "\n",
       "   ...   Salary                                       ApplicationP  \\\n",
       "0  ...      NaN  To apply for this position, please submit a\\r\\...   \n",
       "1  ...      NaN  Please submit a cover letter and resume to:\\r\\...   \n",
       "2  ...      NaN  Please send resume or CV toursula.kazarian@......   \n",
       "3  ...      NaN  Please send cover letter and resume to Amy\\r\\n...   \n",
       "4  ...      NaN  Successful candidates should submit\\r\\n- CV; \\...   \n",
       "\n",
       "  OpeningDate                                       Deadline Notes  \\\n",
       "0         NaN                                26 January 2004   NaN   \n",
       "1         NaN                                12 January 2004   NaN   \n",
       "2         NaN  20 January 2004\\r\\nSTART DATE:  February 2004   NaN   \n",
       "3         NaN      23 January 2004\\r\\nSTART DATE:  Immediate   NaN   \n",
       "4         NaN                         20 January 2004, 18:00   NaN   \n",
       "\n",
       "                                              AboutC Attach  Year Month     IT  \n",
       "0                                                NaN    NaN  2004     1  False  \n",
       "1  The International Research & Exchanges Board (...    NaN  2004     1  False  \n",
       "2  The Caucasus Environmental NGO Network is a\\r\\...    NaN  2004     1  False  \n",
       "3                                                NaN    NaN  2004     1  False  \n",
       "4                                                NaN    NaN  2004     1   True  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19001, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobpost                 0\n",
       "date                    0\n",
       "Title                  28\n",
       "Company                 7\n",
       "AnnouncementCode    17793\n",
       "Term                11325\n",
       "Eligibility         14071\n",
       "Audience            18361\n",
       "StartDate            9326\n",
       "Duration             8203\n",
       "Location               32\n",
       "JobDescription       3891\n",
       "JobRequirment        2522\n",
       "RequiredQual          484\n",
       "Salary               9378\n",
       "ApplicationP           60\n",
       "OpeningDate           706\n",
       "Deadline               65\n",
       "Notes               16790\n",
       "AboutC               6531\n",
       "Attach              17442\n",
       "Year                    0\n",
       "Month                   0\n",
       "IT                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19001 entries, 0 to 19000\n",
      "Data columns (total 24 columns):\n",
      "jobpost             19001 non-null object\n",
      "date                19001 non-null object\n",
      "Title               18973 non-null object\n",
      "Company             18994 non-null object\n",
      "AnnouncementCode    1208 non-null object\n",
      "Term                7676 non-null object\n",
      "Eligibility         4930 non-null object\n",
      "Audience            640 non-null object\n",
      "StartDate           9675 non-null object\n",
      "Duration            10798 non-null object\n",
      "Location            18969 non-null object\n",
      "JobDescription      15110 non-null object\n",
      "JobRequirment       16479 non-null object\n",
      "RequiredQual        18517 non-null object\n",
      "Salary              9623 non-null object\n",
      "ApplicationP        18941 non-null object\n",
      "OpeningDate         18295 non-null object\n",
      "Deadline            18936 non-null object\n",
      "Notes               2211 non-null object\n",
      "AboutC              12470 non-null object\n",
      "Attach              1559 non-null object\n",
      "Year                19001 non-null int64\n",
      "Month               19001 non-null int64\n",
      "IT                  19001 non-null bool\n",
      "dtypes: bool(1), int64(2), object(21)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "trainingData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "\"3rd Generation\" Internship Program                                                       1\n",
       "\"Gavar\" Branch Manager                                                                    1\n",
       "\"Hilti\" Manager                                                                           1\n",
       "\"Hilti\" Subdivision Sales Manager                                                         1\n",
       "\"Hilti\" Subdivision Salesman                                                              1\n",
       "\"Hilti\" Subdivision Service Center Engineer                                               1\n",
       "\"Kamo\" Branch Manager                                                                     1\n",
       "\"Kapan\" Branch Manager                                                                    1\n",
       "\"Malatia\" Branch Manager                                                                  1\n",
       "\"Migration and Development\" Project Manager                                               1\n",
       "\"Promoting Rights of Children & Adolescents with Mental Health                            3\n",
       "\"Sustainable Management of Biodiversity in the Southern Caucasus\"                         1\n",
       "\"The Role of Education in the Process of Overcoming Poverty\"                              1\n",
       "'Doka' Forming Materials Subdivision Chief Engineer/                                      1\n",
       "'Doka' Forming Materials Subdivision Manager                                              1\n",
       "(Chief) Accountant                                                                        1\n",
       ".NET\\r\\nDevelope                                                                          1\n",
       ".NET / SharePoint Developer                                                               1\n",
       ".NET Backend Developer                                                                    1\n",
       ".NET Developer                                                                           36\n",
       ".NET Developer, IT Department                                                             1\n",
       ".NET Engineer                                                                             3\n",
       ".NET Senior Developer                                                                     1\n",
       ".NET Senior Developer C#                                                                  1\n",
       ".NET Senior Software Developer                                                            6\n",
       ".NET Software Developer                                                                  11\n",
       ".NET Software Developer (C#,ASP.NET)                                                      1\n",
       ".NET Solution Developer/ Project Manager                                                  1\n",
       ".NET Team Lead                                                                            2\n",
       ".NET Trainer                                                                              1\n",
       "                                                                                         ..\n",
       "Yerevan Community Internet Centre Manager                                                 1\n",
       "Yerevan Postal Network Head                                                               1\n",
       "Yerevan Transformational Development Facilitator                                          1\n",
       "Yoga and Pilates Instructor                                                               1\n",
       "Young Bankers Program                                                                     1\n",
       "Young Bankers Programme                                                                   3\n",
       "Young Bankers Programme 10                                                                2\n",
       "Young Bankers Programme 9                                                                 1\n",
       "Young Economist - Macroeconomic and Microeconomic Field                                   1\n",
       "Young Economists Possessing Research Potential and Skills                                 1\n",
       "Young Macroeconomist - Monetary Policy Department                                         1\n",
       "Young Specialist in Macroeconomic and Microeconomic Field /                               1\n",
       "Young Specialist, Monetary Policy Department, CBA Dilijan\\r\\nTraining-Research Center     1\n",
       "Youth Facility Educator                                                                   2\n",
       "Youth Segment Marketing Leading Specialist                                                1\n",
       "ZANG Armenia Legal Socialization Program Manager                                          1\n",
       "Zend/ PHP Developer                                                                       1\n",
       "Zonal  Clinical Coordinator                                                               1\n",
       "e-Course ''Strength of Materials''                                                        1\n",
       "eMarketing Training                                                                       2\n",
       "iOS Developer                                                                            31\n",
       "iOS Mobile Application Developer                                                          1\n",
       "iOS Mobile Developer                                                                      1\n",
       "iOS Software Developer                                                                    1\n",
       "iOS Software Engineer                                                                     2\n",
       "iOS/ C++ Expert                                                                           1\n",
       "iOS/ Objective C Developer                                                                1\n",
       "iPhone Application Developer                                                              9\n",
       "iPhone/ iPad Application Developer                                                        3\n",
       "iPhone/ iPad Software Developer                                                           1\n",
       "Name: jobpost, Length: 8636, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.groupby(['Title']).count()['jobpost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "5         1\n",
       "6         1\n",
       "7         1\n",
       "8         1\n",
       "9         1\n",
       "10        1\n",
       "11        1\n",
       "12        1\n",
       "13        1\n",
       "14        1\n",
       "15        1\n",
       "16        1\n",
       "17        1\n",
       "18        1\n",
       "19        1\n",
       "20        1\n",
       "21        1\n",
       "22        1\n",
       "23        1\n",
       "24        1\n",
       "25        1\n",
       "26        1\n",
       "27        1\n",
       "28        1\n",
       "29        1\n",
       "         ..\n",
       "18971    12\n",
       "18972    12\n",
       "18973    12\n",
       "18974    12\n",
       "18975    12\n",
       "18976    12\n",
       "18977    12\n",
       "18978    12\n",
       "18979    12\n",
       "18980    12\n",
       "18981    12\n",
       "18982    12\n",
       "18983    12\n",
       "18984    12\n",
       "18985    12\n",
       "18986    12\n",
       "18987    12\n",
       "18988    12\n",
       "18989    12\n",
       "18990    12\n",
       "18991    12\n",
       "18992    12\n",
       "18993    12\n",
       "18994    12\n",
       "18995    12\n",
       "18996    12\n",
       "18997    12\n",
       "18998    12\n",
       "18999    12\n",
       "19000    12\n",
       "Name: Month, Length: 19001, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData['Month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\nikesh\\anaconda3\\lib\\site-packages (1.26.0)\n",
      "Collecting textract\n",
      "  Using cached https://files.pythonhosted.org/packages/e0/00/a9278b3672a31da06394eb588a16e96f8fce9f6ae0ed44cca18103d4aef5/textract-1.6.1.tar.gz\n",
      "Collecting argcomplete==1.8.2 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/f0/0f/f965f1520e6ba24b63320919eecfbe3d03debd32402e0c61a08e8fa02d17/argcomplete-1.8.2-py2.py3-none-any.whl\n",
      "Collecting chardet==2.3.0 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/7e/5c/605ca2daa5cf21c87690d8fe6ab05a6f2278c451f4ede6456dd26453f4bd/chardet-2.3.0-py2.py3-none-any.whl\n",
      "Collecting python-pptx==0.6.5 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/9c/30bc244cedc571307efe0780d8195ffed5b08f09c94d23f50d6d5144ebc7/python-pptx-0.6.5.tar.gz\n",
      "Collecting docx2txt==0.6 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/aa/72/f02730ec3b0219d8f783a255416339b02ff8b6a300c817abf0505833212a/docx2txt-0.6.tar.gz\n",
      "Collecting beautifulsoup4==4.5.3 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/af/a3/9e803f838b3eeb313d45d916d4387cda8572c92e1aafeb53fd43ddb5da2c/beautifulsoup4-4.5.3-py3-none-any.whl\n",
      "Collecting xlrd==1.0.0 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/0c/b0/8946fe3f9c2690c164aaa88dfd43b56347d3cdeac34124b988acd1aaa151/xlrd-1.0.0-py3-none-any.whl\n",
      "Collecting EbookLib==0.15 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/04/30/2cbf65fa9587a1ecc66a78eea91f9189ead8fdadd5e009115bce34529aa6/EbookLib-0.15.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Nikesh\\AppData\\Local\\Temp\\pip-install-yduqdfb8\\EbookLib\\setup.py\", line 13, in <module>\n",
      "        long_description = open('README.md').read(),\n",
      "      File \"c:\\users\\nikesh\\anaconda3\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "        return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "    UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 1671: character maps to <undefined>\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\Nikesh\\AppData\\Local\\Temp\\pip-install-yduqdfb8\\EbookLib\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\nikesh\\anaconda3\\lib\\site-packages (3.2.4)\n",
      "Requirement already satisfied: six in c:\\users\\nikesh\\anaconda3\\lib\\site-packages (from nltk) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "!pip install textract\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textract\n",
      "  Using cached https://files.pythonhosted.org/packages/e0/00/a9278b3672a31da06394eb588a16e96f8fce9f6ae0ed44cca18103d4aef5/textract-1.6.1.tar.gz\n",
      "Collecting argcomplete==1.8.2 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/f0/0f/f965f1520e6ba24b63320919eecfbe3d03debd32402e0c61a08e8fa02d17/argcomplete-1.8.2-py2.py3-none-any.whl\n",
      "Collecting chardet==2.3.0 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/7e/5c/605ca2daa5cf21c87690d8fe6ab05a6f2278c451f4ede6456dd26453f4bd/chardet-2.3.0-py2.py3-none-any.whl\n",
      "Collecting python-pptx==0.6.5 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/9c/30bc244cedc571307efe0780d8195ffed5b08f09c94d23f50d6d5144ebc7/python-pptx-0.6.5.tar.gz\n",
      "Collecting docx2txt==0.6 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/aa/72/f02730ec3b0219d8f783a255416339b02ff8b6a300c817abf0505833212a/docx2txt-0.6.tar.gz\n",
      "Collecting beautifulsoup4==4.5.3 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/af/a3/9e803f838b3eeb313d45d916d4387cda8572c92e1aafeb53fd43ddb5da2c/beautifulsoup4-4.5.3-py3-none-any.whl\n",
      "Collecting xlrd==1.0.0 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/0c/b0/8946fe3f9c2690c164aaa88dfd43b56347d3cdeac34124b988acd1aaa151/xlrd-1.0.0-py3-none-any.whl\n",
      "Collecting EbookLib==0.15 (from textract)\n",
      "  Using cached https://files.pythonhosted.org/packages/04/30/2cbf65fa9587a1ecc66a78eea91f9189ead8fdadd5e009115bce34529aa6/EbookLib-0.15.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Nikesh\\AppData\\Local\\Temp\\pip-install-32carnn1\\EbookLib\\setup.py\", line 13, in <module>\n",
      "        long_description = open('README.md').read(),\n",
      "      File \"c:\\users\\nikesh\\anaconda3\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "        return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "    UnicodeDecodeError: 'charmap' codec can't decode byte 0x8d in position 1671: character maps to <undefined>\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\Nikesh\\AppData\\Local\\Temp\\pip-install-32carnn1\\EbookLib\\\n"
     ]
    }
   ],
   "source": [
    "!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PyPDF2 \n",
    "#import textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PyPDF2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a for-loop to open many files -- leave a comment if you'd #like to learn how\n",
    "filename = 'Resume.pdf' \n",
    "\n",
    "#open allows you to read the file\n",
    "pdfFileObj = open(filename,'rb')\n",
    "\n",
    "#The pdfReader variable is a readable object that will be parsed\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "#discerning the number of pages will allow us to parse through all #the pages\n",
    "num_pages = pdfReader.numPages\n",
    "count = 0\n",
    "text = \"\"\n",
    "\n",
    "#The while loop will read each page\n",
    "while count < num_pages:\n",
    "    pageObj = pdfReader.getPage(count)\n",
    "    count +=1\n",
    "    text += pageObj.extractText()\n",
    "\n",
    "#This if statement exists to check if the above library returned #words. It's done because PyPDF2 cannot read scanned files.\n",
    "if text != \"\":\n",
    "    text = text\n",
    "\n",
    "#If the above returns as False, we run the OCR library textract to #convert scanned/image based PDF files into text\n",
    "else:\n",
    "    text = textract.process(fileurl, method='tesseract', language='eng')\n",
    "# Now we have a text variable which contains all the text derived #from our PDF file. Type print(text) to see what it contains. It #likely contains a lot of spaces, possibly junk such as '\\n' etc.\n",
    "# Now, we will clean our text variable, and return it as a list of keywords.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nikesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The word_tokenize() function will break our text phrases into #individual words\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "#we'll create a new list which contains punctuation we wish to clean\n",
    "punctuations = ['(',')',';',':','[',']',',']\n",
    "\n",
    "#We initialize the stopwords variable which is a list of words like #\"The\", \"I\", \"and\", etc. that don't hold much value as keywords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#We create a list comprehension which only returns a list of words #that are NOT IN stop_words and NOT IN punctuations.\n",
    "keywords = [word for word in tokens if not word in stop_words and  not word in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sr',\n",
       " 'e',\n",
       " 'er',\n",
       " 'g',\n",
       " 'M',\n",
       " 'nd',\n",
       " 'k',\n",
       " 'hi',\n",
       " 'l',\n",
       " 'Sr',\n",
       " 'e',\n",
       " 'en',\n",
       " 'h',\n",
       " '23',\n",
       " '5',\n",
       " 'P',\n",
       " 'ar',\n",
       " 'k',\n",
       " 'Dr',\n",
       " 'v',\n",
       " 'e',\n",
       " 'Apt',\n",
       " '2',\n",
       " '3',\n",
       " 'B',\n",
       " 'st',\n",
       " 'n',\n",
       " 'M',\n",
       " 'A',\n",
       " '0',\n",
       " '22',\n",
       " '1',\n",
       " '5',\n",
       " '61',\n",
       " '7',\n",
       " '3',\n",
       " '0',\n",
       " '4',\n",
       " '9',\n",
       " '7',\n",
       " '4',\n",
       " '1',\n",
       " 'mandakathil',\n",
       " 'husky.n',\n",
       " 'e',\n",
       " 'u.ed',\n",
       " 'u',\n",
       " 'h',\n",
       " 'tt',\n",
       " 'p',\n",
       " '//',\n",
       " 'l',\n",
       " 'nke',\n",
       " 'n',\n",
       " 'c',\n",
       " 'om/i',\n",
       " 'n',\n",
       " 'r',\n",
       " 'e',\n",
       " 'e',\n",
       " 'r',\n",
       " 'g',\n",
       " 'sr',\n",
       " 'e',\n",
       " 'en',\n",
       " 'h',\n",
       " 'DevOp',\n",
       " 'Engineer',\n",
       " 'Web',\n",
       " 'C',\n",
       " 'loud',\n",
       " 'Developer',\n",
       " 'Io',\n",
       " 'T',\n",
       " 'Data',\n",
       " 'Analyst',\n",
       " 'EDUCATION',\n",
       " 'N',\n",
       " 'th',\n",
       " 'e',\n",
       " 'ast',\n",
       " 'er',\n",
       " 'n',\n",
       " 'U',\n",
       " 'n',\n",
       " 'r',\n",
       " 'si',\n",
       " 'B',\n",
       " 'n',\n",
       " 'M',\n",
       " 'A',\n",
       " 'Master',\n",
       " 'Science',\n",
       " 'Information',\n",
       " 'Systems',\n",
       " 'Expected',\n",
       " 'M',\n",
       " '20',\n",
       " '1',\n",
       " '9',\n",
       " 'Relevant',\n",
       " 'Courses',\n",
       " 'Database',\n",
       " 'Management',\n",
       " 'Systems',\n",
       " 'Advanced',\n",
       " 'Data',\n",
       " 'Scien',\n",
       " 'ce',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'Intelligence',\n",
       " 'sys',\n",
       " 'tem',\n",
       " 'N',\n",
       " 'io',\n",
       " 'na',\n",
       " 'l',\n",
       " 'I',\n",
       " 'nst',\n",
       " 'u',\n",
       " 'e',\n",
       " 'f',\n",
       " 'T',\n",
       " 'ec',\n",
       " 'hno',\n",
       " 'log',\n",
       " 'W',\n",
       " 'ra',\n",
       " 'n',\n",
       " 'g',\n",
       " 'l',\n",
       " 'Te',\n",
       " 'l',\n",
       " 'n',\n",
       " 'g',\n",
       " 'n',\n",
       " 'I',\n",
       " 'n',\n",
       " 'ia',\n",
       " 'B',\n",
       " 'ch',\n",
       " 'e',\n",
       " 'l',\n",
       " 'r',\n",
       " 'f',\n",
       " 'Techno',\n",
       " 'l',\n",
       " 'og',\n",
       " 'E',\n",
       " 'le',\n",
       " 'c',\n",
       " 'tr',\n",
       " 'n',\n",
       " 'ics',\n",
       " 'n',\n",
       " 'C',\n",
       " 'om',\n",
       " 'u',\n",
       " 'n',\n",
       " 'ic',\n",
       " 'n',\n",
       " 'E',\n",
       " 'n',\n",
       " 'g',\n",
       " 'ine',\n",
       " 'e',\n",
       " 'r',\n",
       " 'n',\n",
       " 'g',\n",
       " 'May',\n",
       " '2017',\n",
       " 'Relevant',\n",
       " 'Courses',\n",
       " 'Digital',\n",
       " 'System',\n",
       " 'Design',\n",
       " 'Computer',\n",
       " 'Networks',\n",
       " 'Digital',\n",
       " 'Signal',\n",
       " 'Processing',\n",
       " 'Data',\n",
       " 'Structures',\n",
       " 'Toastmaster',\n",
       " 'International',\n",
       " 'President',\n",
       " 'f',\n",
       " 'Speech',\n",
       " 'Maniacs',\n",
       " 'Gavel',\n",
       " 'Club',\n",
       " 'Kuwait',\n",
       " '2011',\n",
       " '12',\n",
       " 'SKILL',\n",
       " 'Programming',\n",
       " 'Languages',\n",
       " 'C++',\n",
       " 'HTML',\n",
       " 'Python',\n",
       " 'R',\n",
       " 'Java',\n",
       " 'Ruby',\n",
       " 'JQuery',\n",
       " 'Javascript',\n",
       " 'Server',\n",
       " 'side',\n",
       " 'PHP',\n",
       " 'Nodejs',\n",
       " 'Hive',\n",
       " 'Apache',\n",
       " 'Spark',\n",
       " 'Hadoop',\n",
       " 'Ruby',\n",
       " 'Rails',\n",
       " 'Frame',\n",
       " 'Works',\n",
       " 'Code',\n",
       " 'Ignitor',\n",
       " 'Django',\n",
       " 'Firebase',\n",
       " 'Express',\n",
       " 'JS',\n",
       " 'Angular',\n",
       " 'JS',\n",
       " 'Database',\n",
       " 'MySQL',\n",
       " 'NoSQL',\n",
       " 'Oracle',\n",
       " '11g',\n",
       " 'Microsoft',\n",
       " 'SQL',\n",
       " 'Server',\n",
       " 'Firebase',\n",
       " 'Web',\n",
       " 'hosting',\n",
       " 'computation',\n",
       " 'AWS',\n",
       " 'Bluehost',\n",
       " 'Digital',\n",
       " 'Ocean',\n",
       " 'C',\n",
       " 'Panel',\n",
       " 'Python',\n",
       " 'Libraries',\n",
       " 'NLTK',\n",
       " 'Scrapy',\n",
       " 'plotly',\n",
       " 'Tensor',\n",
       " 'flow',\n",
       " 'Keras',\n",
       " 'Matplotlib',\n",
       " 'Pandas',\n",
       " 'bokeh',\n",
       " 'Tools',\n",
       " 'GIT',\n",
       " 'Salesforce',\n",
       " 'Docker',\n",
       " 'T',\n",
       " 'ableau',\n",
       " 'Google',\n",
       " 'Analytics',\n",
       " 'Selenium',\n",
       " 'PROFESSIONAL',\n",
       " 'EXPERIENCE',\n",
       " 'https',\n",
       " '//github.com/sreeragsreenath/',\n",
       " 'Rese',\n",
       " 'rch',\n",
       " 'A',\n",
       " 'sista',\n",
       " 'n',\n",
       " 'I',\n",
       " 'O',\n",
       " 'T',\n",
       " 'Ope',\n",
       " 'n',\n",
       " 'I',\n",
       " 'nn',\n",
       " 'ov',\n",
       " 'io',\n",
       " 'n',\n",
       " 'L',\n",
       " 'ab',\n",
       " 'No',\n",
       " 'r',\n",
       " 'er',\n",
       " 'n',\n",
       " 'U',\n",
       " 'n',\n",
       " 'iv',\n",
       " 'e',\n",
       " 'r',\n",
       " 'ity',\n",
       " 'Bo',\n",
       " 'sto',\n",
       " 'n',\n",
       " 'MA',\n",
       " 'Sep',\n",
       " 't.',\n",
       " '2017',\n",
       " 'Present',\n",
       " 'Develop',\n",
       " 'web',\n",
       " 'platform',\n",
       " 'deployed',\n",
       " 'Amazon',\n",
       " 'EC2',\n",
       " 'instance',\n",
       " 'using',\n",
       " 'round',\n",
       " 'robin',\n",
       " 'sever',\n",
       " 'server',\n",
       " 'task',\n",
       " 'scheduling',\n",
       " 'data',\n",
       " 'kept',\n",
       " 'S3',\n",
       " 'buckets',\n",
       " 'Remove',\n",
       " 'page',\n",
       " 'load',\n",
       " 'time',\n",
       " 'redundancies',\n",
       " 'image',\n",
       " 'code',\n",
       " 'optimization',\n",
       " 'Working',\n",
       " 'AWS',\n",
       " 'Python',\n",
       " 'N',\n",
       " 'ode',\n",
       " 'JS',\n",
       " 'firebase',\n",
       " 'system',\n",
       " 'make',\n",
       " 'th',\n",
       " 'e',\n",
       " 'site',\n",
       " 'r',\n",
       " 'ealtime',\n",
       " 'robust',\n",
       " 'reliable',\n",
       " 'required',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'iotopeninnovation.org',\n",
       " 'Web',\n",
       " 'Master',\n",
       " 'W',\n",
       " 'r',\n",
       " 'l',\n",
       " 'H',\n",
       " 'r',\n",
       " 'A',\n",
       " 'c',\n",
       " 'io',\n",
       " 'n',\n",
       " 'N',\n",
       " 'r',\n",
       " 'hea',\n",
       " 'st',\n",
       " 'er',\n",
       " 'n',\n",
       " 'U',\n",
       " 'ni',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 'Bo',\n",
       " 'n',\n",
       " 'MA',\n",
       " 'Sep',\n",
       " 't.',\n",
       " '2017',\n",
       " 'Jan',\n",
       " '2018',\n",
       " 'Improved',\n",
       " 'Site',\n",
       " 'page',\n",
       " 'speed',\n",
       " 'score',\n",
       " '22',\n",
       " '93',\n",
       " 'GTMetrix',\n",
       " 'Integrated',\n",
       " 'Google',\n",
       " 'analytics',\n",
       " 'improve',\n",
       " 'pages',\n",
       " 'visitor',\n",
       " 'count',\n",
       " 'Migrat',\n",
       " 'ed',\n",
       " 'new',\n",
       " 'server',\n",
       " 'Digital',\n",
       " 'Ocean',\n",
       " 'improve',\n",
       " 'security',\n",
       " 'Encryption',\n",
       " 'SSL',\n",
       " 'Certification',\n",
       " 'efficiency',\n",
       " 'system',\n",
       " 'thewha.org',\n",
       " 'President',\n",
       " 'W',\n",
       " 'e',\n",
       " 'b',\n",
       " 'n',\n",
       " 'S',\n",
       " 'oftwa',\n",
       " 'r',\n",
       " 'e',\n",
       " 'D',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'l',\n",
       " 'op',\n",
       " 'e',\n",
       " 'n',\n",
       " 'C',\n",
       " 'el',\n",
       " 'l',\n",
       " 'N',\n",
       " 'ITW',\n",
       " 'Telangana',\n",
       " 'In',\n",
       " 'Aug',\n",
       " '2014',\n",
       " 'Ap',\n",
       " 'r',\n",
       " 'il',\n",
       " '2017',\n",
       " 'Engineered',\n",
       " 'Hostel',\n",
       " 'allotment',\n",
       " 'Student',\n",
       " 'semester',\n",
       " 'Registrati',\n",
       " 'Institute',\n",
       " 'website',\n",
       " 'Systems',\n",
       " 'www.nitw.ac.in',\n",
       " 'Programmed',\n",
       " 'PHP',\n",
       " 'Django',\n",
       " 'Python',\n",
       " 'Angular',\n",
       " 'Docker',\n",
       " 'NodeJS',\n",
       " 'deployed',\n",
       " 'help',\n",
       " 'Octopus',\n",
       " 'Led',\n",
       " 'Government',\n",
       " 'Projects',\n",
       " 'Telangana',\n",
       " 'Police',\n",
       " 'implement',\n",
       " 'internal',\n",
       " 'Information',\n",
       " 'Management',\n",
       " 'System',\n",
       " 'wsdc.nitw.ac.in',\n",
       " 'AC',\n",
       " 'A',\n",
       " 'D',\n",
       " 'E',\n",
       " 'MI',\n",
       " 'C',\n",
       " 'P',\n",
       " 'R',\n",
       " 'O',\n",
       " 'J',\n",
       " 'ECT',\n",
       " 'S',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'With',\n",
       " 'Energy',\n",
       " 'Dataset',\n",
       " 'Advanced',\n",
       " 'Data',\n",
       " 'Science',\n",
       " 'Boston',\n",
       " 'MA',\n",
       " 'March',\n",
       " '2018',\n",
       " 'Conducted',\n",
       " 'EDA',\n",
       " 'feature',\n",
       " 'analysis',\n",
       " 'using',\n",
       " 'Python',\n",
       " 'libraries',\n",
       " 'plo',\n",
       " 'tly',\n",
       " 'seaborn',\n",
       " 'matplotlib',\n",
       " 'Implemented',\n",
       " 'Linear',\n",
       " 'Random',\n",
       " 'Forest',\n",
       " 'Neural',\n",
       " 'Networks',\n",
       " 'Tensorflow',\n",
       " 'build',\n",
       " 'prediction',\n",
       " 'model',\n",
       " 'python',\n",
       " 'Tested',\n",
       " 'various',\n",
       " 'features',\n",
       " 'influence',\n",
       " 'output',\n",
       " 'Explore',\n",
       " 'tpot',\n",
       " 'featuretools',\n",
       " 'Boruta',\n",
       " 'tsfresh',\n",
       " 'https',\n",
       " '//goo.gl/hBvq3g',\n",
       " 'Github',\n",
       " 'Link',\n",
       " 'Pipelined',\n",
       " 'deployed',\n",
       " 'EC2',\n",
       " 'instance',\n",
       " 't2.micro',\n",
       " 'data',\n",
       " 'saved',\n",
       " 'S3',\n",
       " 'buckets',\n",
       " 'Medical',\n",
       " 'record',\n",
       " 'analysis',\n",
       " 'system',\n",
       " 'B.Tech',\n",
       " 'Final',\n",
       " 'Project',\n",
       " 'Telangana',\n",
       " 'India',\n",
       " 'Jan',\n",
       " '2017',\n",
       " 'Feb.',\n",
       " '2017',\n",
       " 'Project',\n",
       " 'read',\n",
       " 'MRI',\n",
       " 'images',\n",
       " 'data',\n",
       " 'detect',\n",
       " 'brain',\n",
       " 'tumor',\n",
       " 'using',\n",
       " 'Convolutional',\n",
       " 'Neural',\n",
       " 'Networks',\n",
       " 'Computed',\n",
       " 'model',\n",
       " 'using',\n",
       " 'Amazon',\n",
       " 'Ec2',\n",
       " 'instance',\n",
       " 'C5',\n",
       " '2Xlarge',\n",
       " 'instance',\n",
       " 'took',\n",
       " '40',\n",
       " 'mins',\n",
       " 'process',\n",
       " 'Developed',\n",
       " 'Web',\n",
       " 'application',\n",
       " 'interface',\n",
       " 'database',\n",
       " 'interact',\n",
       " 'patient',\n",
       " 'data',\n",
       " 'https',\n",
       " '//goo.gl/Q1MYHo',\n",
       " 'A',\n",
       " 'l',\n",
       " 'bas',\n",
       " 'e',\n",
       " 'l',\n",
       " 'u',\n",
       " 'mn',\n",
       " 'w',\n",
       " 'e',\n",
       " 'b',\n",
       " 'c',\n",
       " 'rap',\n",
       " 'n',\n",
       " 'g',\n",
       " 'application',\n",
       " 'Lakshya',\n",
       " 'Hackathon',\n",
       " 'Telangana',\n",
       " 'India',\n",
       " 'Feb',\n",
       " '2016',\n",
       " 'Designed',\n",
       " 'pytho',\n",
       " 'n',\n",
       " 'b',\n",
       " 'crappe',\n",
       " 'r',\n",
       " 'application',\n",
       " 'fo',\n",
       " 'r',\n",
       " 'company',\n",
       " 'Almabas',\n",
       " 'e',\n",
       " 'https',\n",
       " '//goo.gl/fhfmx3',\n",
       " 'Perfor',\n",
       " 'ed',\n",
       " 'Text',\n",
       " 'Senti',\n",
       " 'ent',\n",
       " 'A',\n",
       " 'nalysis',\n",
       " 'w',\n",
       " 'eb',\n",
       " 'scraped',\n",
       " 'news',\n",
       " 'articles',\n",
       " 'find',\n",
       " 'relevance',\n",
       " 'ACHIEVEMENTS',\n",
       " 'Microsoft',\n",
       " 'Code.Fun.do',\n",
       " '2015',\n",
       " 'Mozilla',\n",
       " 'Hackathon',\n",
       " '2014']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sr\\ne\\ner\\na\\ng\\n \\nM\\na\\nnd\\na\\nk\\nat\\nhi\\nl\\n \\nSr\\ne\\nen\\nat\\nh\\n \\n23\\n5\\n \\nP\\nar\\nk\\n \\nDr\\ni\\nv\\ne\\n,\\n \\nApt.\\n2\\n3\\n,\\n \\nB\\no\\nst\\no\\nn\\n,\\n \\nM\\nA\\n \\n0\\n22\\n1\\n5\\n \\n|\\n61\\n7\\n-\\n3\\n0\\n4\\n-\\n9\\n7\\n4\\n1\\n|\\n \\nmandakathil.\\ns\\n@\\nhusky.n\\ne\\nu.ed\\nu\\n \\n|\\n \\nh\\ntt\\np\\ns:\\n//\\nl\\ni\\nnke\\nd\\ni\\nn\\n.\\nc\\nom/i\\nn\\n/\\ns\\nr\\ne\\ne\\nr\\na\\ng\\nsr\\ne\\nen\\na\\nt\\nh\\n \\nDevOp\\n \\nEngineer\\n \\n\\nWeb\\n \\nand C\\nloud\\n \\nDeveloper\\n \\n\\nIo\\nT \\n\\nData Analyst\\ns\\n \\nEDUCATION \\n \\n_\\n_\\n \\nN\\nor\\nth\\ne\\nast\\ner\\nn\\n \\nU\\nn\\ni\\nve\\nr\\nsi\\nt\\ny\\n \\n|\\n \\nB\\no\\ns\\nt\\no\\nn\\n,\\n \\nM\\nA\\n \\nMaster of Science in \\nInformation Systems\\n                                                                                        \\nExpected\\n \\nM\\na\\ny\\n \\n20\\n1\\n9\\n \\n-\\n \\nRelevant Courses: Database Management Systems, Advanced Data Scien\\nce, Big Data & Intelligence sys\\ntem \\n \\nN\\na\\nt\\nio\\nna\\nl\\n \\nI\\nnst\\nit\\nu\\nt\\ne\\n \\no\\nf\\n \\nT\\nec\\nhno\\nlog\\ny\\n \\nW\\na\\nra\\nn\\ng\\na\\nl\\n \\n|    \\nTe\\nl\\na\\nn\\ng\\na\\nn\\na\\n,\\n \\nI\\nn\\nd\\nia\\n \\nB\\na\\nch\\ne\\nl\\no\\nr\\n \\no\\nf\\n \\nTechno\\nl\\nog\\ny\\n \\nin\\n \\nE\\nle\\nc\\ntr\\no\\nn\\nics\\n \\na\\nn\\nd\\n \\nC\\nom\\nm\\nu\\nn\\nic\\nat\\ni\\no\\nn\\n \\nE\\nn\\ng\\nine\\ne\\nr\\ni\\nn\\ng\\n                                    \\n      \\n   \\n         \\n \\nMay 2017\\n \\n      \\n \\n-\\n \\nRelevant Courses:\\n \\nDigital System Design, Computer Networks, Digital Signal Processing, Data Structures\\n \\n-\\n \\nToastmaster \\nInternational\\n: President\\n \\no\\nf Speech Maniacs Gavel Club, Kuwait \\n(2011\\n-\\n12)\\n \\nSKILL                                                                                 \\n                                                                                      \\n \\nProgramming Languages\\n:\\n \\nC++, HTML, Python,\\n \\nR,\\n \\nJava\\n, Ruby\\n, JQuery\\n, Javascript\\n \\nServer side\\n:\\n \\nPHP\\n,\\n \\nNodejs\\n,\\n \\nHive \\n, \\nApache Spark, Hadoop\\n, Ruby on Rails\\n \\nFrame Works\\n:\\n \\nCode \\nIgnitor, Django,\\n \\nFirebase\\n, Express JS\\n, Angular JS\\n \\nDatabase\\n:\\n \\nMySQL, NoSQL, Oracle 11g, Microsoft SQL Server, \\nFirebase\\n \\nWeb hosting and computation\\n:\\n \\nAWS, Bluehost, Digital Ocean, C Panel\\n \\nPython Libraries\\n:\\n \\nNLTK, Scrapy, \\nplotly, \\nTensor\\n \\nflow, Keras\\n, Matplotlib, Pandas\\n, bokeh\\n \\n \\nTools: \\n \\nGIT,\\n \\nSalesforce\\n, \\nDocker, \\nT\\nableau\\n,\\n \\nGoogle Analytics\\n, \\nSelenium\\n \\n \\nPROFESSIONAL EXPERIENCE \\n \\n                                                          \\n     \\nhttps://github.com/sreeragsreenath/\\n                                                            \\n \\nRese\\na\\nrch\\n \\nA\\ns\\nsista\\nn\\nt\\n, \\nI\\nO\\nT\\n \\nOpe\\nn\\n \\nI\\nnn\\nov\\na\\nt\\nio\\nn\\n \\nL\\nab\\ns\\n,\\n \\nNo\\nr\\nt\\nhe\\nas\\nt\\ner\\nn\\n \\nU\\nn\\niv\\ne\\nr\\ns\\nity\\n \\n|\\n \\nBo\\nsto\\nn\\n,\\n \\nMA \\n       \\n \\n  \\nSep\\nt.\\n \\n2017 \\n\\n \\nPresent\\n \\n\\n \\nDevelop\\n \\na web \\nplatform and deployed it on Amazon EC2 instance using round robin \\nsever server task \\nscheduling with data kept at S3 buckets.\\n \\n \\n\\n \\nRemove\\n \\npage load time redundancies\\n \\nby image and code optimization\\n \\n \\n\\n \\nWorking on\\n \\nAWS, \\nPython,\\n \\nN\\node\\n-\\nJS\\n \\nand firebase system to make th\\ne site \\nr\\nealtime\\n,\\n \\nrobust and \\nreliable\\n \\nwith the required data analytics\\n \\n(\\niotopeninnovation.org\\n)\\n \\n \\nWeb Master\\n, \\nW\\no\\nr\\nl\\nd\\n \\nH\\ni\\ns\\nto\\nr\\ny\\n \\nA\\ns\\nso\\nc\\ni\\na\\nt\\nio\\nn\\n,\\n \\nN\\no\\nr\\nt\\nhea\\nst\\ner\\nn\\n \\nU\\nni\\nv\\ne\\nr\\ns\\ni\\nt\\ny\\n \\n|\\n \\nBo\\ns\\nt\\no\\nn\\n,\\n \\nMA\\n                  \\nSep\\nt. \\n2017 \\n\\n \\nJan\\n. \\n2018\\n \\n\\n \\nImproved Site page speed score \\nfrom 22% to 93% (GTMetrix)\\n,\\n \\nIntegrated Google analytics to \\nimprove pages and visitor count\\n \\n\\n \\nMigrat\\ned\\n \\nto a new server \\n(\\nDigital Ocean\\n)\\n \\nto improve security\\n \\n(Encryption and SSL Certification)\\n \\nand efficiency of the system\\n \\n(\\nthewha.org\\n)\\n \\nPresident\\n, \\nW\\ne\\nb\\n \\na\\nn\\nd\\n \\nS\\noftwa\\nr\\ne\\n \\nD\\ne\\nv\\ne\\nl\\nop\\nm\\ne\\nn\\nt\\n \\nC\\nel\\nl\\n \\na\\nt\\n \\nN\\nITW\\n|\\n \\nTelangana\\n,\\n \\nIn\\nd\\ni\\na\\n  \\n                \\nAug\\n. \\n2014 \\n\\n \\nAp\\nr\\nil\\n \\n2017\\n \\n\\n \\nEngineered\\n \\nHostel allotment, Student semester Registrati\\non and Institute website Systems(\\nwww.nitw.ac.in\\n)\\n \\n\\n \\nProgrammed\\n \\non PHP, Django, Python, Angular\\n, Docker\\n, NodeJS\\n \\nand deployed with help of Octopus\\n \\n\\n \\nLed\\n \\nGovernment\\n \\nProjects with Telangana Police to implement its internal\\n \\nInformation \\nManagement System\\n \\n(\\nwsdc.nitw.ac.in\\n)\\n \\nAC\\nA\\n \\nD\\n \\nE\\nMI\\nC\\n \\n \\nP\\nR\\nO\\nJ\\nECT\\nS\\n \\n \\n   \\n \\nMachine Learning With Energy Dataset \\n \\n| \\nAdvanced Data Science \\n| \\nBoston\\n, \\nMA\\n \\n \\nMarch\\n \\n2018\\n \\n\\n \\nConducted EDA and feature analysis using Python \\nlibraries (plo\\ntly, seaborn, matplotlib \\n)\\n \\n \\n\\n \\nImplemented\\n \\nLinear Random Forest, Neural Networks\\n,\\n \\nTensorflow to build prediction\\n \\nmodel in\\n \\npython. \\n \\n\\n \\nTested \\nvarious features and how \\nthey \\ninfluence the output. Explore\\nd\\n \\ntpot, \\nfeaturetools, Boruta, tsfresh\\n \\n(\\nhttps://goo.gl/hBvq3g\\n \\n-\\n \\nGithub Link)\\n \\n\\n \\nPipelined it and deployed on EC2 instance t2.micro\\n, with data saved in S3 buckets.\\n \\nMedical record analysis system\\n \\n| \\nB.Tech. Final Project\\n \\n| \\nTelangana\\n, India\\n                 \\nJan\\n. \\n2017\\n \\n-\\n \\nFeb.  2017\\n \\n\\n \\nProject \\nto read MRI images\\n \\ndata\\n \\nand to detect brain tumor using Convolutional Neural Networks\\n \\n\\n \\nComputed the model using Amazon Ec2 instance \\n\\n \\nC5 2Xlarge instance, took 40 mins to process\\n \\n\\n \\nDeveloped \\nWeb application interface and database to \\ninteract with patient data\\n(\\nhttps://goo.gl/Q1MYHo\\n)\\n \\nA\\nl\\nm\\na\\nbas\\ne\\n \\na\\nl\\nu\\nmn\\ni\\n \\nw\\ne\\nb\\n \\ns\\nc\\nrap\\ni\\nn\\ng\\n \\napplication\\n \\n| Lakshya Hackathon | \\nTelangana\\n, India\\n \\n \\nFeb\\n.\\n \\n2016\\n \\n\\n \\nDesigned\\n \\na \\npytho\\nn \\nwe\\nb s\\ncrappe\\nr \\napplication \\nfo\\nr \\nthe company \\nAlmabas\\ne\\n(\\nhttps://goo.gl/fhfmx3\\n)\\n \\n\\n \\nPerfor\\nm\\ned Text and Senti\\nm\\nent \\nA\\nnalysis on the \\nw\\neb scraped news articles\\n \\nto find relevance\\n \\nACHIEVEMENTS\\n \\n \\n   \\n \\nMicrosoft Code.Fun.do (2015)\\n \\n \\n \\n \\n \\nMozilla Hackathon (2014)\\n \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doneeeeeeeeeeeeee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next, we define a function to parse the documents (CVs) and save the word embeddings as follows:\n",
    "def preprocess_training_data1(dir_cvs, dir_model_name):    \n",
    "    dircvs = [join(dir_cvs, f) for f in listdir(dir_cvs) if isfile(join(dir_cvs, f))]\n",
    "    alltext = ' '  \n",
    "    for cv in dircvs:\n",
    "        yd = read_All_CV(cv)\n",
    "        alltext += yd + \" \"    \n",
    "    alltext = alltext.lower()\n",
    "    vector = []\n",
    "    for sentence in es.parsetree(alltext, tokenize=True, lemmata=True, tags=True):\n",
    "        temp = []\n",
    "        for chunk in sentence.chunks:\n",
    "            for word in chunk.words:\n",
    "                if word.tag == 'NN' or word.tag == 'VB':\n",
    "                    temp.append(word.lemma)\n",
    "        vector.append(temp)\n",
    "    global model\n",
    "    model = Word2Vec(vector, size=200, window=5, min_count=3, workers=4)\n",
    "    model.save(dir_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class Resume():\n",
    "    def __init__(self,filename):\n",
    "        self.filepath = filename\n",
    "        self.load()\n",
    "        self.parse()\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.filepath,'rb') as f:\n",
    "            self.content = f.read().splitlines()\n",
    "\n",
    "    def checkLine(self,word,value, content, line):\n",
    "        if word in content.lower():\n",
    "            value = self.addValue(value,line)\n",
    "        return value\n",
    "\n",
    "    def addValue(self,value,line):\n",
    "        value[line] = value.get(line,0) + 1\n",
    "        return value\n",
    "\n",
    "    def dict_List(self,dict_, content):\n",
    "        new = [(key,value) for key,value in dict_.items() if dict_[key] == max(dict_.values())]\n",
    "        return [(x[0],content[x[0]]) for x in sorted(new)]\n",
    "\n",
    "    def get_name(self):\n",
    "        names = []\n",
    "        for each in self.name:\n",
    "            if each[0] not in self.headings:\n",
    "                each = each[1].replace('Name',\"\")\n",
    "                if each[0] not in string.letters:\n",
    "                    each = each[1:]\n",
    "                names.append(each.strip())\n",
    "            else:\n",
    "                index = self.headings[self.headings.index(each[0])+1]\n",
    "                names.append(\"\\n\".join(self.content[each[0]+1:index]))\n",
    "        if len(names) == 1:\n",
    "            return names[0]\n",
    "        else:\n",
    "            return names\n",
    "\n",
    "    def get_work(self):\n",
    "        experience = []\n",
    "        for each in self.work:\n",
    "            index = self.headings[self.headings.index(each[0])+1]\n",
    "            experience.append(\"\\n\".join(self.content[each[0]+1:index]))\n",
    "        if len(experience) == 1:\n",
    "            return experience[0]\n",
    "        else:\n",
    "            return epxerience\n",
    "\n",
    "    def parse(self):\n",
    "        name = dict()\n",
    "        work_experience = dict()\n",
    "        isHeading = dict()\n",
    "        for line_num in range(len(self.content)):\n",
    "            for checkName in [\"name\",\":\"]:\n",
    "                name.update(self.checkLine(checkName,name,self.content[line_num], line_num))\n",
    "            for checkWork in [\"work\",\"experience\"]:\n",
    "                work_experience.update(self.checkLine(checkWork,work_experience, self.content[line_num],line_num))\n",
    "            if line_num != len(self.content) - 1:\n",
    "                if len(self.content[line_num + 1]) > len(self.content[line_num]):\n",
    "                    isHeading.update(self.addValue(isHeading,line_num))\n",
    "            if line_num > 0:\n",
    "                if self.content[line_num - 1] == \"\":\n",
    "                    isHeading.update(self.addValue(isHeading,line_num))\n",
    "            if len(self.content[line_num]) == len(self.content[line_num].lstrip()):\n",
    "                isHeading.update(self.addValue(isHeading,line_num))\n",
    "            if self.content[line_num] == \"\":\n",
    "                isHeading[line_num] = isHeading.get(line_num,0) - 1\n",
    "\n",
    "        self.name = self.dict_List(name, self.content)\n",
    "        self.work = self.dict_List(work_experience, self.content)\n",
    "        self.headings = self.dict_List(isHeading, self.content)\n",
    "        self.headings = [x[0] for x in self.headings]\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume = Resume(filename = 'Resume.txt')\n",
    "    print resume.get_name()\n",
    "    print resume.get_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikesh\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "rmse_dict = {}    \n",
    "def rmse(correct,estimated):\n",
    "    rmse_val = np.sqrt(mean_squared_error(correct,estimated)) \n",
    "    return rmse_val\n",
    "\n",
    "# Generating the Table Frame for metrics\n",
    "evluation_table = pd.DataFrame({  'Model_desc':[],\n",
    "                        'Model_param':[],\n",
    "                        'r2_train': [],\n",
    "                        'r2_test': [],\n",
    "                        'rms_train':[], \n",
    "                        'rms_test': [],\n",
    "                        'mae_train': [],\n",
    "                        'mae_test': [],\n",
    "                        'mape_train':[],\n",
    "                        'mape_test':[],\n",
    "                        'cross_val_score' : []})\n",
    "\n",
    "\n",
    "# Evaluating the model\n",
    "def evaluate_model(model, model_desc,model_param, X_train, y_train, X_test, y_test):\n",
    "    global evluation_table\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "    except:\n",
    "        r2_train = \"not calculated\"\n",
    "        r2_test = \"not calculated\"\n",
    "    try:\n",
    "        rms_train = rmse(y_train, y_train_pred)\n",
    "        rms_test = rmse(y_test, y_test_pred)\n",
    "    except:\n",
    "        rms_train = \"not calculated\"\n",
    "        rms_test = \"not calculated\"\n",
    "    try:\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    except:\n",
    "        mae_train = \"not calculated\"\n",
    "        mae_test = \"not calculated\"\n",
    "    try:\n",
    "        mape_train = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
    "        mape_test = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
    "    except:\n",
    "        mape_train = \"not calculated\"\n",
    "        mape_test = \"not calculated\"    \n",
    "    try:\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=10)\n",
    "        cv_score = cv_score.mean()\n",
    "    except:\n",
    "        cv_score = \"Not calulated\"\n",
    "        \n",
    "    model_param = pd.DataFrame({'Model_desc':[model_desc],\n",
    "                            'Model_param':[model_param],\n",
    "                            'r2_train': [r2_train],\n",
    "                            'r2_test': [r2_test],\n",
    "                            'rms_train':[rms_train], \n",
    "                            'rms_test': [rms_test],\n",
    "                            'mae_train': [mae_train],\n",
    "                            'mae_test': [mae_test],\n",
    "                            'mape_train':[mape_train],\n",
    "                            'mape_test':[mape_test],\n",
    "                            'cross_val_score' : [cv_score]})\n",
    "\n",
    "    evluation_table = evluation_table.append([model_param])\n",
    " \n",
    "    return evluation_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
